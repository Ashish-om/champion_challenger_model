{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber transformers torch\n",
        "\n",
        "import pdfplumber\n",
        "from transformers import pipeline, BartTokenizer\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Check for GPU availability\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the Champion Model (Improved Extractor Model)\n",
        "extractor_model = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\",  # Using a free model instead\n",
        "    tokenizer=\"facebook/bart-large-cnn\",\n",
        "    max_length=250,  # Increased max tokens\n",
        "    min_length=50,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    framework=\"pt\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Load the Challenger Model (Zero-Shot Classification for Evaluation)\n",
        "evaluator_model = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"MoritzLaurer/deberta-v3-base-zeroshot-v1\",  # Efficient for classification\n",
        "    framework=\"pt\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Load tokenizer for BART\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file using pdfplumber.\"\"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
        "    return text if text else \"No text extracted from PDF.\"\n",
        "\n",
        "def split_text_into_chunks(text, max_words=700, overlap=100):\n",
        "    \"\"\"Splits large text into overlapping chunks to retain context.\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words - overlap)]\n",
        "    return chunks\n",
        "\n",
        "def champion_model(input_text, additional_context=None):\n",
        "    \"\"\"\n",
        "    Extract relevant information using a summarization model.\n",
        "    Ensures that input text does not exceed the model's max token limit.\n",
        "    \"\"\"\n",
        "    full_input = additional_context + \"\\n\" + input_text if additional_context else input_text\n",
        "\n",
        "    # Tokenize and truncate if necessary\n",
        "    tokens = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    truncated_text = tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
        "\n",
        "    # Generate summary with extended length for better response\n",
        "    summary = extractor_model(truncated_text, max_length=250, min_length=80, do_sample=True, top_k=50, top_p=0.95)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "def challenger_model(champion_response):\n",
        "    \"\"\"Challenger model evaluates the extracted text and provides critique.\"\"\"\n",
        "    labels = [\n",
        "        \"highly accurate and relevant\", \"contains minor inconsistencies\", \"lacks clarity\",\n",
        "        \"contains irrelevant content\", \"needs significant improvement\"\n",
        "    ]\n",
        "    result = evaluator_model(champion_response, candidate_labels=labels)\n",
        "\n",
        "    best_label = result[\"labels\"][0]\n",
        "    score = result[\"scores\"][0]\n",
        "\n",
        "    if best_label == \"highly accurate and relevant\" and score > 0.75:\n",
        "        rating = 9\n",
        "        feedback = \"The extracted information is well-structured and relevant.\"\n",
        "    elif best_label == \"contains minor inconsistencies\":\n",
        "        rating = 7\n",
        "        feedback = \"There are minor inconsistencies. Consider refining key points.\"\n",
        "    elif best_label == \"lacks clarity\":\n",
        "        rating = 6\n",
        "        feedback = \"The response could be clearer and better structured.\"\n",
        "    elif best_label == \"contains irrelevant content\":\n",
        "        rating = 5\n",
        "        feedback = \"Contains irrelevant content. Focus more on extracting key details.\"\n",
        "    else:\n",
        "        rating = 4\n",
        "        feedback = \"Needs significant improvement. Refine and focus more on relevance.\"\n",
        "\n",
        "    return rating, feedback\n",
        "\n",
        "def champion_challenger_pipeline(pdf_path, max_iterations=3):\n",
        "    \"\"\"Pipeline to extract text, refine it iteratively, and return the best response.\"\"\"\n",
        "    extracted_text = extract_text_from_pdf(pdf_path)\n",
        "    if extracted_text == \"No text extracted from PDF.\":\n",
        "        print(\"Error: PDF contains no extractable text.\")\n",
        "        return \"\"\n",
        "\n",
        "    text_chunks = split_text_into_chunks(extracted_text, max_words=700, overlap=100)\n",
        "    final_responses = []\n",
        "\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        print(f\"\\nProcessing Chunk {i+1}/{len(text_chunks)}...\")\n",
        "        iteration = 0\n",
        "        additional_context = \"\"\n",
        "\n",
        "        while iteration < max_iterations:\n",
        "            iteration += 1\n",
        "            print(f\"\\nIteration {iteration}: Champion Model Processing...\\n\")\n",
        "            champion_response = champion_model(chunk, additional_context)\n",
        "            print(\"Champion Model Response:\", champion_response)\n",
        "\n",
        "            rating, feedback = challenger_model(champion_response)\n",
        "            print(f\"Challenger Model Rating: {rating}/10\")\n",
        "            print(f\"Challenger Feedback: {feedback}\\n\")\n",
        "\n",
        "            if rating >= 8:\n",
        "                print(\"Final refined response for this chunk accepted.\")\n",
        "                final_responses.append(champion_response)\n",
        "                break\n",
        "\n",
        "            additional_context = feedback  # Use feedback as guidance\n",
        "            time.sleep(2)  # Prevent excessive looping\n",
        "\n",
        "        if iteration == max_iterations:\n",
        "            print(\"Max iterations reached. Using best available response for this chunk.\")\n",
        "            final_responses.append(champion_response)\n",
        "\n",
        "    final_output = \"\\n\\n\".join(final_responses)\n",
        "    return final_output\n",
        "\n",
        "# Set your PDF file path\n",
        "pdf_path = \"/content/Ashish_22ucc026.pdf\"  # Replace with actual file\n",
        "\n",
        "# Run the pipeline\n",
        "final_response = champion_challenger_pipeline(pdf_path)\n",
        "\n",
        "# Print the extracted relevant information\n",
        "print(\"\\nFinal Extracted Information:\")\n",
        "print(final_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_tebbSqQyyL",
        "outputId": "5cc90e19-de8e-4c0a-d0ce-78b85b272842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Chunk 1/8...\n",
            "\n",
            "Iteration 1: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: This paper presents a comprehensive technical analysis of application patterns and use cases. We evaluate existing FaaS practitioners. platforms, both commercial offerings and open-source solutions, comparing theirperformancecharacteristics,scalabilityfeatures, and development workflows. We examine emerging trends including edge-based FAAS deployment, hybrid archi- tectures, and specialized hardware acceleration for serverless A. Execution Model and Infrastructure workloads. Through experimental evaluation and case studies, we proposeimplementationstrategiesforefficientFaaSadoption.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "\n",
            "Iteration 2: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: Function-as-a-Service (FaaS) represents one of the most significant paradigm shifts in this evolution. Cloud computing continues to evolve rapidly, with each ment advancement aiming to abstract infrastructure management. FaaS platforms employ a multi-tenant execution environ- in various technical domains including IoT systems, machine ment wherefunctioninstancesareisolated usingcontaineriza- learning pipelines, and real-time data processing applications.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "\n",
            "Iteration 3: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: Function-as-a-Service (FaaS) represents one of the most significant paradigm shifts in cloud computing. FaaS platforms employ a multi-tenant execution environ- in various technical domains including IoT systems, machine ment wherefunctioninstancesareisolated. Cloud computing continues to evolve rapidly, with each advancement aiming to abstract infrastructure management. This workcontributestothetechnicalunderstanding of serverless technology.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "Max iterations reached. Using best available response for this chunk.\n",
            "\n",
            "Processing Chunk 2/8...\n",
            "\n",
            "Iteration 1: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: Google Cloud Functions of- FaaS platforms implement sophisticated event processing fers tight integration with other Google Cloud services and systems. IBMCloudFunctions: BasedontheApacheOpenWhisk based on incoming request volume, with platforms like AWS platform, IBM Cloud Functions offers a unique technical Lambda able to scale to thousands of concurrent executions within seconds. Microsoft’s Azure Functions provides 4) Error Handling: Dead-letter queues and retry mecha- uniquecapabilitiesforintegrationwith.NETecosystems. Google Cloud Functions: Extension enabling stateful orches- trationworkflowsthroughfunctionchaining.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "\n",
            "Iteration 2: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: Some FaaS implementations offer within a VPC, enabling access to private resources. Google Cloud Functions implement sophisticated event processing fers tight integration with other Google Cloud services and systems to handle function invocation at scale. IBMCloudFunctions: BasedontheApacheOpenWhisk based on incoming request volume, with platforms like AWS platform, IBM Cloud Functions offers a unique technical Lambda able to scale to thousands of concurrent executions.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "\n",
            "Iteration 3: Champion Model Processing...\n",
            "\n",
            "Champion Model Response: Some FaaS implementations offer within a VPC, enabling access to private resources. Google Cloud Functions implement sophisticated event processing fers tight integration with other Google Cloud services and systems to handle function invocation at scale. IBM Cloud Functions offers a unique technical Lambda able to scale to thousands of concurrent executions architecture within seconds. Auto-scaling Mechanisms in patterns, and human interaction are key.\n",
            "Challenger Model Rating: 6/10\n",
            "Challenger Feedback: The response could be clearer and better structured.\n",
            "\n",
            "Max iterations reached. Using best available response for this chunk.\n",
            "\n",
            "Processing Chunk 3/8...\n",
            "\n",
            "Iteration 1: Champion Model Processing...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qeavcv7kTnq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}